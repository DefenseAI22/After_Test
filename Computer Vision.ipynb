{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e259fb50-fd19-417b-897b-480865242f64",
   "metadata": {},
   "source": [
    "### 1. 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "907711b3-9be2-465f-b1ba-af3a8f3aee82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shinjoohwan/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, random, time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83f457c-4580-40ed-ad3a-0f4e9b7814ea",
   "metadata": {},
   "source": [
    "### 2. 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02312471-e23d-4c5e-9993-a7dabdbfa57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 디바이스 ▶ cpu\n",
      "num_workers  ▶ 0\n",
      "pin_memory   ▶ False\n"
     ]
    }
   ],
   "source": [
    "# ────────────────── 1. 디바이스 자동 선택 ──────────────────\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    PIN_MEM  = True          # CUDA일 때만 의미 있음\n",
    "    NUM_WORKERS = os.cpu_count()  # 병렬 로딩\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    PIN_MEM  = False\n",
    "    NUM_WORKERS = 0\n",
    "\n",
    "print(\"사용 디바이스 ▶\", device)\n",
    "print(\"num_workers  ▶\", NUM_WORKERS)\n",
    "print(\"pin_memory   ▶\", PIN_MEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d424ee0-a4e5-41c4-a4a1-4896065e4201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 데이터 디렉터리 ---\n",
    "train_root = Path(\"./train\")  # Train 디렉터리를 가리키는 Path 객체\n",
    "test_root  = Path(\"./test\")   # Test 디렉터리를 가리키는 Path 객체\n",
    "csv_path   = Path(\"./train_data.csv\")  # 첫 열: 이미지 파일명\n",
    "\n",
    "# --- 학습 파라미터 ---\n",
    "BATCH_SIZE  = 32\n",
    "EPOCHS      = 20\n",
    "LR          = 3e-4\n",
    "VAL_RATIO   = 0.2\n",
    "SEED        = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1361ced3-6590-4cfd-85ee-21d5ed1f1406",
   "metadata": {},
   "source": [
    "### 3. SEED 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a252906b-f607-42af-83b3-b5cba84fa1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark     = False\n",
    "\n",
    "set_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4709b1a6-9097-4e56-94d8-2091052a4557",
   "metadata": {},
   "source": [
    "### 4. 데이터셋 클래스\n",
    "- Dataset: 인덱스로 개별 샘플을 읽어는 방법 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5bc9326-bfdd-47e6-865b-d0b3a36a850b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeskDataset(Dataset):\n",
    "    \"\"\"\n",
    "    이미지 파일 목록을 받아 인덱스로 접근할 때마다 -> (이미지, 라벨) or (이미지, 파일명) 반환\n",
    "    \n",
    "    files: 이미지 파일 경로의 리스트\n",
    "    test: 테스트 모드 여부. True면 라벨을 반환하지 않고 (이미지, 파일명)만 제공\n",
    "    transform: 이미지 전처리 파이프라인\n",
    "    \"\"\"\n",
    "    def __init__(self, files, test=False, transform=None):\n",
    "        self.files = files\n",
    "        self.test = test\n",
    "        self.transform = transform or transforms.Compose([])\n",
    "\n",
    "        if not test:\n",
    "            # 파일명에 unclean 포함되면 1, 그렇지 않으면 0\n",
    "            self.lbl_fn = lambda p: 1 if \"unclean\" in p.name.lower() else 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.files[idx] # 인덱스로 이미지 파일 경로를 얻는다.\n",
    "        img = Image.open(img_path).convert(\"RGB\") # 이미지 열고 채널 수를 3개(RGB)로 맞춘다.\n",
    "        img = self.transform(img) # 전처리(Resize, Normalize 등) 적용\n",
    "        if self.test: # 테스트 모드면 라벨에 없으므로 (이미지 텐서, 파일명) 반환하고 종료\n",
    "            return img, img_path.name\n",
    "        label = self.lbl_fn(img_path) # 훈련.검증 모드인 경우, 파일명을 이용해 라벨(0/1) 계산\n",
    "        return img, torch.tensor(label, dtype=torch.long) # 이미지 텐서, 라벨 텐서 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fe8720-2cb0-42e5-92ab-fe0b5e62717b",
   "metadata": {},
   "source": [
    "### 5. 전처리 & DataLoader\n",
    "- DataLoader: Dataset을 배치 단위로 묶어 GPU에 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3638f568-8d68-470a-933b-4519e4a8e853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 사전 학습 weight 및 메타 정보 로드 ─────────────\n",
    "weights = EfficientNet_V2_S_Weights.DEFAULT # torchvision에 포함된 공식 사전 학습 가중치 선택\n",
    "preprocess = weights.transforms() \n",
    "IMG_SIZE = preprocess.crop_size[0]         # (384,) 형태 튜플 → 384\n",
    "MEAN, STD = preprocess.mean, preprocess.std\n",
    "\n",
    "# ── 파일 수집 ─────────────────────────────────────\n",
    "exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\"} # exts: 허용할 이미지 확장자 집합(set)\n",
    "# rglob(*): train_root 하위 모든 경로를 검색\n",
    "train_files = sorted([p for p in train_root.rglob(\"*\") if p.suffix.lower() in exts]) # train_root: Path(./train)로 지정된 디렉토리\n",
    "test_files  = sorted([p for p in test_root .rglob(\"*\") if p.suffix.lower() in exts])\n",
    "# p.suffix: 파일의 확장자(ex .JPG)\n",
    "# sorted(): 필터링된 Path 객체들을 이름순으로 정렬 -> 이렇게 하면 인덱스가 고정돼 재현성 확보\n",
    "\n",
    "# ── Stratified Train/Val Split ───────────────────\n",
    "# train_files에 들어 있는 학습용 이미지 목록을 라벨 정보와 함께 훈련 / 검증 세트로 나누는 작업\n",
    "y_all = [1 if \"unclean\" in p.name.lower() else 0 for p in train_files]\n",
    "train_f, val_f = train_test_split(\n",
    "    train_files, # 분할할 원본 리스트\n",
    "    test_size=VAL_RATIO, \n",
    "    random_state=SEED,\n",
    "    stratify=y_all # 라벨 분포 유지\n",
    ")\n",
    "\n",
    "# ── Transform ────────────────────────────────────\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8,1.0), ratio=(0.95,1.05)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.15,0.15,0.15,0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(MEAN, STD),\n",
    "])\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Resize(int(IMG_SIZE*1.15)),   # 384*1.15 ≈ 442\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(MEAN, STD),\n",
    "])\n",
    "\n",
    "# ── Dataset & DataLoader ─────────────────────────\n",
    "# Dataset\n",
    "train_ds = DeskDataset(train_f, transform=train_tf)\n",
    "val_ds   = DeskDataset(val_f,   transform=val_tf)\n",
    "test_ds  = DeskDataset(test_files, test=True, transform=val_tf)\n",
    "\n",
    "# DataLoader\n",
    "# 내부에서 Dataset.__getitem__을 동시에 여러 번 호출해 미리 배치 단위 텐서로 묶어 주기 때문에, 학습 루프에서는 모델 연산에만 집중\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                      num_workers=NUM_WORKERS, pin_memory=True) # pin_memory: CPU 메모리를 잠금(pin)하여 GPU로 복사 속도 향상(CUDA 사용 시 효과)\n",
    "val_dl   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,\n",
    "                      num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_dl  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False,\n",
    "                      num_workers=NUM_WORKERS, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb5e772-7e09-4ab8-832f-b235e2cf923d",
   "metadata": {},
   "source": [
    "### 6. 모델 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80964207-3a0d-44af-bc9f-11cf7c2700cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = efficientnet_v2_s(weights=weights)\n",
    "in_features = model.classifier[1].in_features # model.classifier는 Dropout -> Linear(1280, 1000) 형테\n",
    "# model.classifier[1]을 통해 입력 차원 1280을 읽어옴\n",
    "model.classifier = nn.Sequential( # 기존 1000 클래스 Linear를 2-클래스 Linear로 교체\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(in_features, 2)    # 2-class\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.AdamW(model.parameters(), # 학습할 파라미터 전체\n",
    "                              lr=LR, \n",
    "                              weight_decay=1e-4 # L2 regularization\n",
    "                             )\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "# (1) Early-Stopping 변수 선언\n",
    "best_acc          = 0.0   # 최고 검증 정확도\n",
    "PATIENCE          = 4     # 허용할 연속 미개선 epoch 수\n",
    "epochs_no_improve = 0     # 연속으로 개선되지 않은 횟수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6af541c-4293-49a1-b88b-759c0daff897",
   "metadata": {},
   "source": [
    "### 7. 학습 루프 & best_model.h5 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62be56a8-6f59-4a07-a87d-dd9be34782e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, loader):\n",
    "    model.train() # 훈련 모드\n",
    "    total_loss, total_correct = 0, 0 # 한 에포크 동안 평균 손실과 정확도를 계산하기 위해 합계를 저장할 변수를 0으로 초기화\n",
    "    for imgs, labels in tqdm(loader, leave=False): # loader가 배치 단위로 (이미지, 라벨) 튜플을 공급 / tqdm: 진행률 바 표시\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True) # 지난 배치에소 계산된 기울기를 0으로 리셋\n",
    "        logits = model(imgs) # 모델에 이미지 배치를 넣어 로짓(logits)을 얻는다.\n",
    "        loss   = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step() # 기울기에 따라 가중치를 한 스텝 갱신\n",
    "        total_loss += loss.item() * len(labels)\n",
    "        total_correct += (logits.argmax(1) == labels).sum().item() # 로짓의 최댓값 인덱스(argmax[1])가 정답과 일치하는 개수를 더한다.\n",
    "    return total_loss / len(loader.dataset), total_correct / len(loader.dataset)\n",
    "\n",
    "@torch.no_grad() # 자동 미분 끄기. 평가 시 기울기 계산, 저장을 하지 않아 메모리와 연산 절약\n",
    "def eval_epoch(model, loader):\n",
    "    model.eval() # 평가 모드. 드롭아웃 끄고, 배치 정규화는 이동평균, 분산을 사용\n",
    "    total_loss, total_correct = 0, 0\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        logits = model(imgs)\n",
    "        loss   = criterion(logits, labels)\n",
    "        total_loss += loss.item() * len(labels)\n",
    "        total_correct += (logits.argmax(1) == labels).sum().item()\n",
    "    return total_loss / len(loader.dataset), total_correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c6ef90c-f219-4116-93b3-fabfe90fe401",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shinjoohwan/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/20] Train  78.10% | Valid  88.57%\n",
      "  ↳ 새 최고 정확도: 88.57% (모델 저장)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/20] Train  98.54% | Valid  94.29%\n",
      "  ↳ 새 최고 정확도: 94.29% (모델 저장)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/20] Train 100.00% | Valid  97.14%\n",
      "  ↳ 새 최고 정확도: 97.14% (모델 저장)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/20] Train 100.00% | Valid 100.00%\n",
      "  ↳ 새 최고 정확도: 100.00% (모델 저장)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/20] Train 100.00% | Valid 100.00%\n",
      "  ↳ 개선 없음 (1/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06/20] Train 100.00% | Valid 100.00%\n",
      "  ↳ 개선 없음 (2/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/20] Train 100.00% | Valid 100.00%\n",
      "  ↳ 개선 없음 (3/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08/20] Train 100.00% | Valid 100.00%\n",
      "  ↳ 개선 없음 (4/4)\n",
      "\n",
      "4 epoch 연속 개선이 없어 학습을 조기 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "for ep in range(1, EPOCHS + 1):\n",
    "    tr_loss, tr_acc = train_epoch(model, train_dl)\n",
    "    val_loss, val_acc = eval_epoch(model, val_dl)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"[{ep:02}/{EPOCHS}] \"\n",
    "          f\"Train {tr_acc*100:6.2f}% | Valid {val_acc*100:6.2f}%\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        torch.save(model, \"best_model.h5\")\n",
    "        print(f\"  ↳ 새 최고 정확도: {best_acc*100:.2f}% (모델 저장)\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"  ↳ 개선 없음 ({epochs_no_improve}/{PATIENCE})\")\n",
    "\n",
    "    if epochs_no_improve >= PATIENCE:\n",
    "        print(f\"\\n{PATIENCE} epoch 연속 개선이 없어 학습을 조기 종료합니다.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19467826-68e4-4493-b6f3-cd31e3976771",
   "metadata": {},
   "source": [
    "### 8. train_data.csv -> 예측 컬럼 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be658dfe-487d-4cea-b14e-f3414a0c5535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 결과를 'train_data_with_pred.csv'에 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "# ── 1. 최고 성능 모델 불러오기 ───────────────────\n",
    "best_model = efficientnet_v2_s(weights=None)         # 구조만 생성\n",
    "in_features = best_model.classifier[1].in_features\n",
    "best_model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(in_features, 2)\n",
    ")\n",
    "best_model.load_state_dict(\n",
    "    torch.load(\"best_model.pth\", map_location=device)  # 저장한 state_dict 로드\n",
    ")\n",
    "best_model = best_model.to(device).eval()\n",
    "\n",
    "# ── 2. test_dl에 대해 예측 ───────────────────────\n",
    "preds, fnames = [], []\n",
    "with torch.no_grad(): # 기울기 저장 X\n",
    "    for imgs, names in test_dl:        # DataLoader가 배치 단위 (이미지 텐서, 파일명 리스트) 제공\n",
    "        imgs = imgs.to(device)\n",
    "        logits = best_model(imgs)\n",
    "        preds.extend(logits.argmax(1).cpu().tolist())  # 0/1 예측값\n",
    "        fnames.extend(names)                           # 이미지 파일명\n",
    "\n",
    "# ── 3. 예측 결과 DataFrame 생성 ───────────────────\n",
    "pred_df = pd.DataFrame({\"fname\": fnames, \"pred\": preds})\n",
    "\n",
    "# ── 4. 기존 CSV 읽어와서 예측 열 추가 ─────────────\n",
    "df = pd.read_csv(csv_path)            # header가 이미 있다고 가정\n",
    "fname_col = df.columns[0]             # 첫 번째 열(파일명 열) 이름\n",
    "df[\"pred\"] = df[fname_col].map(       # 파일명 기준으로 매핑\n",
    "    dict(zip(pred_df.fname, pred_df.pred))\n",
    ")\n",
    "\n",
    "# ── 5. 저장 ──────────────────────────────────────\n",
    "out_path = csv_path.with_name(\"train_data_with_pred.csv\")\n",
    "df.to_csv(out_path, index=False)\n",
    "print(f\"예측 결과를 '{out_path}'에 저장했습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b48a2a-25ad-4086-a47c-b10f0fea6058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4027cc58-5f99-418c-ba86-fa7390fa9b54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base]",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
